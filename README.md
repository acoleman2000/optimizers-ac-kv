# George Washington Neural Network
Group: Alex Coleman and Kyle Vitale. 

This repository contains a neural network library built from scratch for use in Neural Network courses at
The George Washington University. It is a basic implementation that provides a number of layers, activation
functions, and loss functions for students to explore how networks work at a low level. 

For this Neural Networks Fall 2022 final project, we will be implementing and testing SGD and ADAM optimizers as opposed to the default GD optimizer.